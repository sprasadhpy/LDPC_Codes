{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systematic Encoding Matrix Generator Function\n",
    "\n",
    "This function is designed to receive a parity check matrix $H$ and build a systematic encoding matrix $G$ for it. The process involves potentially renaming the variables to ensure systematic encoding.\n",
    "\n",
    "## Function Description\n",
    "\n",
    "- **Input**: The function takes a parity check matrix $H$.\n",
    "- **Processing**: It rearranges $H$ to $\\hat{H}$, which is equal to $H$ up to a column permutation. Then, it constructs a systematic encoding matrix $G$.\n",
    "- **Output**: The function returns two matrices:\n",
    "  - $\\hat{H}$: A rearranged version of $H$ after column permutation.\n",
    "  - $G$: A systematic encoding matrix such that $\\hat{H}Gt = 0$ in $F_{2}$ (the field of two elements).\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- All operations must be performed in the finite field $F_{2}$ (binary field).\n",
    "- The matrix $G$ should be constructed in a way that it satisfies the condition $\\hat{H}Gt = 0$.\n",
    "\n",
    "## Example\n",
    "\n",
    "Consider testing the function with the following matrix $H$:\n",
    "\n",
    "$H = \\begin{bmatrix}\n",
    "  1 & 1 & 1 & 1 & 0 & 0 \\\\\n",
    "  0 & 0 & 1 & 1 & 0 & 1 \\\\\n",
    "  1 & 0 & 0 & 1 & 1 & 0 \n",
    "    \\end{bmatrix}$\n",
    "\n",
    "The function should return matrices $\\hat{H}$ and $G$ for this input. Note that this function may also be tested with other input matrices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 0 0]\n",
      " [0 0 1 1 0 1]\n",
      " [1 0 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "H = np.array([[1,1,1,1,0,0],\n",
    "              [0,0,1,1,0,1],\n",
    "              [1,0,0,1,1,0]],dtype=int)\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 0., -0.,  1.],\n",
       "       [ 1.,  1.,  0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl, u = lu(H, permute_l=True)\n",
    "pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.,  0.,  0.],\n",
       "       [ 0., -1., -1.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.,  1.,  0.,  1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LU decomposition: https://www.youtube.com/watch?v=BFYFkn-eOQk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Description\n",
    "\n",
    "### Function Purpose\n",
    "The function `generator_matrix` takes a parity check matrix $H$ and constructs a systematic encoding matrix $G$ for it.\n",
    "\n",
    "### Parameters\n",
    "- $H$: A parity check matrix, represented as a 2D array or matrix.\n",
    "\n",
    "### Returns\n",
    "- $\\hat{H}$: A matrix equal to $H$ up to a column permutation.\n",
    "- $G$: The systematic encoding matrix constructed from $H$.\n",
    "\n",
    "### Constraints\n",
    "- $H$ should be a valid non-empty matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_matrix(parity_check_matrix):\n",
    "    \n",
    "    def to_reduced_row_echelon_form(matrix):\n",
    "        \n",
    "        rows, cols = matrix.shape    \n",
    "        pivot_row = pivot_col = row_to_swap = 0\n",
    "        echelon_matrix = matrix.copy()\n",
    "\n",
    "        while True:\n",
    "            if pivot_row >= rows or pivot_col >= cols:\n",
    "                break\n",
    "\n",
    "            # If the current entry is zero, find a non-zero row to swap\n",
    "            if echelon_matrix[pivot_row, pivot_col] == 0:\n",
    "                row_to_swap = pivot_row\n",
    "                while row_to_swap < rows and echelon_matrix[row_to_swap, pivot_col] == 0:\n",
    "                    row_to_swap += 1\n",
    "\n",
    "                # If no non-zero entry is found in the column, move to the next column\n",
    "                if row_to_swap == rows:\n",
    "                    pivot_col += 1\n",
    "                    continue\n",
    "\n",
    "                # Swap the rows\n",
    "                echelon_matrix[pivot_row, :], echelon_matrix[row_to_swap, :] = echelon_matrix[row_to_swap, :].copy(), echelon_matrix[pivot_row, :].copy()\n",
    "\n",
    "            # Row elimination to create zeros in all other rows of current column\n",
    "            for current_row in range(rows):\n",
    "                if current_row != pivot_row and echelon_matrix[current_row, pivot_col] != 0:\n",
    "                    echelon_matrix[current_row, :] = (echelon_matrix[current_row, :] + echelon_matrix[pivot_row, :]) % 2\n",
    "\n",
    "            # Move to the next element in the diagonal\n",
    "            pivot_row += 1\n",
    "            pivot_col += 1\n",
    "\n",
    "        return echelon_matrix\n",
    "\n",
    "    # Calculate the dimensions of the parity check matrix\n",
    "    rows, cols = parity_check_matrix.shape\n",
    "\n",
    "    # Calculate the dimension k of the code\n",
    "    code_dimension = cols - rows\n",
    "\n",
    "    # Convert the parity check matrix to its reduced row echelon form\n",
    "    echelon_matrix = to_reduced_row_echelon_form(parity_check_matrix)\n",
    "\n",
    "    # Directly construct the generator matrix\n",
    "    generator_matrix = np.vstack((echelon_matrix[:, rows:cols], np.identity(code_dimension, dtype=int)))\n",
    "\n",
    "    return echelon_matrix, generator_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H_hat:\n",
      " [[1 0 0 1 1 0]\n",
      " [0 1 0 1 1 1]\n",
      " [0 0 1 1 0 1]] \n",
      "G:\n",
      " [[1 1 0]\n",
      " [1 1 1]\n",
      " [1 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "H_hat, G = generator_matrix(H)\n",
    "\n",
    "print(\"H_hat:\\n\",H_hat, \"\\nG:\\n\", G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDPC Decoder Implementation Using Loopy Belief Propagation\n",
    "\n",
    "### Task\n",
    "Develop an LDPC decoder based on Loopy Belief Propagation suitable for a Binary Symmetric Channel.\n",
    "\n",
    "### Function Specifications\n",
    "- **Inputs**:\n",
    "  - $\\hat{H}$: (Parity Check Matrix)\n",
    "  - $y$: (Received Word)\n",
    "  - $p$: (Noise Ratio)\n",
    "  - $max\\_iterations$: (Optional, Maximum Number of Iterations; default value: 20)\n",
    "\n",
    "- **Output**:\n",
    "  - Decoded vector\n",
    "  - Return code:\n",
    "    - $0$: for success\n",
    "    - $-1$: if the maximum number of iterations is reached without successful decoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 shape: (750, 1000)\n",
      "y1 shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "with open(\"H1.txt\") as file_h:\n",
    "    h1 = np.array([list(map(int, line.split())) for line in file_h if line.strip()], dtype=int)\n",
    "\n",
    "print(\"h1 shape: \" + str(h1.shape))\n",
    "\n",
    "with open(\"y1.txt\") as file_y:\n",
    "    y1 = np.array([int(line.strip()) for line in file_y if line.strip()], dtype=int)\n",
    "\n",
    "print(\"y1 shape: \" + str(y1.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(parity_check_matrix, received_signal, noise_ratio=.1, maximum_iterations=20):\n",
    "\n",
    "    decoding_success = -1\n",
    "    num_rows, num_cols = parity_check_matrix.shape\n",
    "\n",
    "    # List of factor checks\n",
    "    bit_check_indices = []\n",
    "    for row in range(num_rows):\n",
    "        bit_check_indices.append(np.where(parity_check_matrix[row] == 1)[0])\n",
    "\n",
    "    # Probability calculations\n",
    "    probability_signal_given_bit_one = np.zeros(len(received_signal))\n",
    "    probability_signal_given_bit_zero = np.zeros(len(received_signal))\n",
    "\n",
    "    for i in range(len(received_signal)):\n",
    "        probability_signal_given_bit_one[i] = (noise_ratio ** ((received_signal[i] + 1) % 2) * \n",
    "                                               (1 - noise_ratio) ** ((received_signal[i] + 2) % 2))\n",
    "        probability_signal_given_bit_zero[i] = (noise_ratio ** (received_signal[i]) * \n",
    "                                                (1 - noise_ratio) ** ((received_signal[i] + 1) % 2))\n",
    "\n",
    "    # Initialize message matrix\n",
    "    message_matrix = np.zeros((num_rows, num_cols))\n",
    "\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            message_matrix[row, col] = (np.log([probability_signal_given_bit_zero[col] / \n",
    "                                                probability_signal_given_bit_one[col]]))\n",
    "    \n",
    "    for iteration in range(maximum_iterations):\n",
    "        \n",
    "        # Factor to variable message matrix\n",
    "        message_factor_variable = np.zeros((num_rows, num_cols))\n",
    "\n",
    "        for index in range(len(bit_check_indices)):\n",
    "            new_row = np.zeros(num_cols)\n",
    "            product = message_matrix[index, (bit_check_indices[index])]\n",
    "            \n",
    "            for i in range(len(product)):\n",
    "                product_excluding_self = np.hstack((product[0:i], product[i + 1: len(product)]))\n",
    "                product_result = np.prod(np.tanh(product_excluding_self / 2))\n",
    "                log_value = (1 + product_result) / (1 - product_result)\n",
    "                new_row[bit_check_indices[index][i]] = np.log(log_value)\n",
    "            \n",
    "            message_factor_variable[index, :] = new_row\n",
    "\n",
    "        # Calculate log likelihood of posterior\n",
    "        posterior_log_likelihood = np.sum(message_factor_variable, axis=0)\n",
    "        \n",
    "        for i in range(num_cols):\n",
    "            posterior_log_likelihood[i] += (np.log([probability_signal_given_bit_zero[i] / \n",
    "                                                    probability_signal_given_bit_one[i]]))\n",
    "        \n",
    "        # Update prediction\n",
    "        decoded_signal = np.zeros(num_cols)\n",
    "        for i in range(num_cols):\n",
    "            decoded_signal[i] = 0 if posterior_log_likelihood[i] > 0 else 1\n",
    "            \n",
    "        # Test for parity conditions\n",
    "        parity_test = np.matmul(parity_check_matrix, decoded_signal.T) % 2\n",
    "\n",
    "        # Check if parity conditions are met or maximum iterations reached\n",
    "        if iteration == maximum_iterations or np.all(parity_test == 0):\n",
    "            decoding_success = 0\n",
    "            break\n",
    "        else:\n",
    "            # Update variable to factor message\n",
    "            for col in range(num_cols):\n",
    "                for row in range(num_rows):\n",
    "                    message_matrix[row, col] = posterior_log_likelihood[col] - message_factor_variable[row, col]\n",
    "    \n",
    "    return decoding_success, iteration + 1, decoded_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "success, iter, decoded = decode(h1, y1, noise_ratio=0.1, maximum_iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success: 0 \n",
      " iteration: 8 \n",
      " decoded result: \n",
      "[0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      " 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1.\n",
      " 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0.\n",
      " 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1.\n",
      " 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0.\n",
      " 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1.\n",
      " 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
      " 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0.\n",
      " 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1.\n",
      " 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1.\n",
      " 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1.\n",
      " 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1.\n",
      " 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"success: \" + str(success), \"\\n\", \"iteration: \" + str(iter), \"\\n\", \"decoded result: \" + \"\\n\" + str(decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy Holidays! Dmitry&David :)\n"
     ]
    }
   ],
   "source": [
    "x = np.reshape(decoded.astype(int), (125, 8)).astype(str)\n",
    "\n",
    "b = [''.join(row) for row in x]\n",
    "\n",
    "message = ''.join(chr(int(binary, 2)) for binary in b[:31])\n",
    "\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
